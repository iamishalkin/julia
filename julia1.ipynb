{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from skimage import transform, filters, exposure\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6220, 20, 20, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from natsort import natsorted\n",
    "from scipy.misc import imread\n",
    "import random\n",
    "random.seed( 42 ) \n",
    "\n",
    "# Path of data files\n",
    "path = \"/home/ivan/python/julia/data\"\n",
    " \n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    " \n",
    " \n",
    "\n",
    "### Images preprocessing ###\n",
    "\n",
    "for setType in [\"test\",\"train\"]:\n",
    "    # We have to make sure files are sorted according to labels, even if they don't have trailing zeros\n",
    "    files = natsorted(glob.glob(path + \"/\"+setType+\"/*\"))\n",
    "    \"\"\"\n",
    "    if setType == 'test':\n",
    "        X_test = np.array([np.array(Image.open(fname)) for fname in files])\n",
    "    else:\n",
    "        X_train = np.array([np.array(Image.open(fname)) for fname in files])\n",
    "    \"\"\"\n",
    "    if setType == 'test':\n",
    "        X_test = np.array([np.array(imread(fname, flatten=True)) for fname in files])\n",
    "    else:\n",
    "        X_train = np.array([np.array(imread(fname, flatten=True)) for fname in files])\n",
    "X_test=X_test[:,:,:,np.newaxis]\n",
    "X_train=X_train[:,:,:,np.newaxis]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_test.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label2int(ch):\n",
    "    asciiVal = ord(ch)\n",
    "    if(asciiVal<=57): #0-9\n",
    "        asciiVal-=48\n",
    "    elif(asciiVal<=90): #A-Z\n",
    "        asciiVal-=55\n",
    "    else: #a-z\n",
    "        asciiVal-=61\n",
    "    return asciiVal\n",
    "    \n",
    "def int2label(i):\n",
    "    if(i<=9): #0-9\n",
    "        i+=48\n",
    "    elif(i<=35): #A-Z\n",
    "        i+=55\n",
    "    else: #a-z\n",
    "        i+=61\n",
    "    return chr(i)\n",
    "# Load labels\n",
    "y_train = pd.read_csv(\"/home/ivan/python/julia/trainLabels.csv\").values[:,1] #Keep only label\n",
    " \n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    " \n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1 # One-hot\n",
    "Y_train_all = Y_train.copy()\n",
    "X_train_all = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = \\\n",
    "        train_test_split(X_train_all, Y_train_all, test_size=0.2, stratify=np.argmax(Y_train_all, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 62 # A-Z, a-z and 0-9\n",
    "nb_epoch = 500\n",
    "img_rows, img_cols = 20, 20\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Convolution2D(3, 3, 128,  border_mode='same', init='he_normal', activation = 'relu', input_shape=(1, img_rows, img_cols)))\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", input_shape=(img_rows, img_cols, 1), padding=\"same\"))\n",
    "model.add(Conv2D(32, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", padding=\"same\"))\n",
    "\n",
    "model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(64, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", padding=\"same\"))\n",
    "\n",
    "model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", padding=\"same\"))\n",
    "model.add(Conv2D(128, (3, 3), kernel_initializer=\"he_normal\", activation=\"relu\", padding=\"same\"))\n",
    "\n",
    "model.add(MaxPooling2D(data_format=\"channels_last\", pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2048, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2048, kernel_initializer=\"he_normal\", activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, kernel_initializer=\"he_normal\", activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LEARNING ###\n",
    " \n",
    "# First, use AdaDelta for some epochs because AdaMax gets stuck\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adadelta',  \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5026 samples, validate on 1257 samples\n",
      "Epoch 1/20\n",
      "5026/5026 [==============================] - 37s - loss: 3.8828 - acc: 0.0611 - val_loss: 3.8377 - val_acc: 0.0660\n",
      "Epoch 2/20\n",
      "5026/5026 [==============================] - 37s - loss: 3.7641 - acc: 0.0965 - val_loss: 3.6786 - val_acc: 0.1233\n",
      "Epoch 3/20\n",
      "5026/5026 [==============================] - 37s - loss: 3.5462 - acc: 0.1590 - val_loss: 3.2171 - val_acc: 0.2299\n",
      "Epoch 4/20\n",
      "5026/5026 [==============================] - 37s - loss: 2.9507 - acc: 0.2969 - val_loss: 3.0054 - val_acc: 0.2792\n",
      "Epoch 5/20\n",
      "5026/5026 [==============================] - 39s - loss: 2.3524 - acc: 0.3991 - val_loss: 2.2795 - val_acc: 0.3930\n",
      "Epoch 6/20\n",
      "5026/5026 [==============================] - 38s - loss: 1.9426 - acc: 0.4895 - val_loss: 1.9688 - val_acc: 0.5004\n",
      "Epoch 7/20\n",
      "5026/5026 [==============================] - 37s - loss: 1.6416 - acc: 0.5575 - val_loss: 1.8071 - val_acc: 0.5076\n",
      "Epoch 8/20\n",
      "5026/5026 [==============================] - 38s - loss: 1.4138 - acc: 0.6142 - val_loss: 1.3525 - val_acc: 0.6221\n",
      "Epoch 9/20\n",
      "5026/5026 [==============================] - 37s - loss: 1.2289 - acc: 0.6514 - val_loss: 1.3532 - val_acc: 0.6173\n",
      "Epoch 10/20\n",
      "5026/5026 [==============================] - 37s - loss: 1.0869 - acc: 0.6825 - val_loss: 1.1484 - val_acc: 0.6961\n",
      "Epoch 11/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.9501 - acc: 0.7228 - val_loss: 1.1237 - val_acc: 0.7033\n",
      "Epoch 12/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.8848 - acc: 0.7386 - val_loss: 1.0498 - val_acc: 0.7112\n",
      "Epoch 13/20\n",
      "5026/5026 [==============================] - 38s - loss: 0.7559 - acc: 0.7797 - val_loss: 1.0820 - val_acc: 0.6929\n",
      "Epoch 14/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.6863 - acc: 0.7929 - val_loss: 1.1929 - val_acc: 0.6945\n",
      "Epoch 15/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.6253 - acc: 0.8084 - val_loss: 1.1503 - val_acc: 0.6786\n",
      "Epoch 16/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.5490 - acc: 0.8291 - val_loss: 1.1053 - val_acc: 0.7033\n",
      "Epoch 17/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.4851 - acc: 0.8460 - val_loss: 1.0479 - val_acc: 0.7239\n",
      "Epoch 18/20\n",
      "5026/5026 [==============================] - 37s - loss: 0.4209 - acc: 0.8655 - val_loss: 1.1664 - val_acc: 0.7096\n",
      "Epoch 19/20\n",
      "5026/5026 [==============================] - 39s - loss: 0.3863 - acc: 0.8776 - val_loss: 1.1492 - val_acc: 0.7200\n",
      "Epoch 20/20\n",
      "5026/5026 [==============================] - 40s - loss: 0.3354 - acc: 0.8868 - val_loss: 1.1615 - val_acc: 0.7017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fab36e49208>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 epochs is sufficient\n",
    "model.fit(X_train, Y_train, batch_size=128,\n",
    "                    #nb_epoch=20, \n",
    "                    epochs=20,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parametrize the image augmentation class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.15,\n",
    "    height_shift_range = 0.15,\n",
    "    shear_range = 0.4,\n",
    "    zoom_range = 0.3,                    \n",
    "    channel_shift_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., verbose=1, steps_per_epoch=39, epochs=500, callbacks=[<keras.ca..., validation_data=(array([[[...)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 2.8203 - acc: 0.3078Epoch 00000: val_acc improved from -inf to 0.63962, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 2.8159 - acc: 0.3081 - val_loss: 1.3249 - val_acc: 0.6396\n",
      "Epoch 2/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 2.2762 - acc: 0.4080Epoch 00001: val_acc improved from 0.63962 to 0.66826, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 34s - loss: 2.2837 - acc: 0.4060 - val_loss: 1.1810 - val_acc: 0.6683\n",
      "Epoch 3/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 2.0626 - acc: 0.4508Epoch 00002: val_acc improved from 0.66826 to 0.70008, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 37s - loss: 2.0616 - acc: 0.4506 - val_loss: 1.0694 - val_acc: 0.7001\n",
      "Epoch 4/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.9310 - acc: 0.4830Epoch 00003: val_acc improved from 0.70008 to 0.71122, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 36s - loss: 1.9268 - acc: 0.4836 - val_loss: 1.0077 - val_acc: 0.7112\n",
      "Epoch 5/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.9170 - acc: 0.4911Epoch 00004: val_acc improved from 0.71122 to 0.74145, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.9108 - acc: 0.4923 - val_loss: 0.9602 - val_acc: 0.7414\n",
      "Epoch 6/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.8154 - acc: 0.5051Epoch 00005: val_acc did not improve\n",
      "39/39 [==============================] - 34s - loss: 1.8133 - acc: 0.5063 - val_loss: 0.9435 - val_acc: 0.7295\n",
      "Epoch 7/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.7724 - acc: 0.5218Epoch 00006: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.7740 - acc: 0.5212 - val_loss: 0.9306 - val_acc: 0.7399\n",
      "Epoch 8/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.6567 - acc: 0.5576Epoch 00007: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.6529 - acc: 0.5568 - val_loss: 0.9364 - val_acc: 0.7399\n",
      "Epoch 9/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.6409 - acc: 0.5533Epoch 00008: val_acc did not improve\n",
      "39/39 [==============================] - 34s - loss: 1.6390 - acc: 0.5534 - val_loss: 0.9054 - val_acc: 0.7407\n",
      "Epoch 10/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.6256 - acc: 0.5550Epoch 00009: val_acc improved from 0.74145 to 0.75259, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.6190 - acc: 0.5562 - val_loss: 0.8868 - val_acc: 0.7526\n",
      "Epoch 11/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.5501 - acc: 0.5718Epoch 00010: val_acc improved from 0.75259 to 0.76691, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.5511 - acc: 0.5709 - val_loss: 0.8466 - val_acc: 0.7669\n",
      "Epoch 12/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.4898 - acc: 0.5878Epoch 00011: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.4934 - acc: 0.5863 - val_loss: 0.8344 - val_acc: 0.7486\n",
      "Epoch 13/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.4982 - acc: 0.5785Epoch 00012: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.4998 - acc: 0.5776 - val_loss: 0.8740 - val_acc: 0.7534\n",
      "Epoch 14/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.4378 - acc: 0.6088Epoch 00013: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.4390 - acc: 0.6078 - val_loss: 0.8555 - val_acc: 0.7589\n",
      "Epoch 15/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.4894 - acc: 0.5807Epoch 00014: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.4824 - acc: 0.5822 - val_loss: 0.8199 - val_acc: 0.7589\n",
      "Epoch 16/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.4101 - acc: 0.6020Epoch 00015: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.4100 - acc: 0.6021 - val_loss: 0.8159 - val_acc: 0.7637\n",
      "Epoch 17/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.4107 - acc: 0.6019Epoch 00016: val_acc improved from 0.76691 to 0.77247, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.4094 - acc: 0.6023 - val_loss: 0.7803 - val_acc: 0.7725\n",
      "Epoch 18/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.3799 - acc: 0.6056Epoch 00017: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.3810 - acc: 0.6055 - val_loss: 0.8160 - val_acc: 0.7621\n",
      "Epoch 19/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.3040 - acc: 0.6218Epoch 00018: val_acc did not improve\n",
      "39/39 [==============================] - 36s - loss: 1.3065 - acc: 0.6209 - val_loss: 0.8331 - val_acc: 0.7422\n",
      "Epoch 20/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2891 - acc: 0.6382Epoch 00019: val_acc did not improve\n",
      "39/39 [==============================] - 36s - loss: 1.2854 - acc: 0.6390 - val_loss: 0.7939 - val_acc: 0.7637\n",
      "Epoch 21/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 1.3073 - acc: 0.6311Epoch 00020: val_acc did not improve\n",
      "39/39 [==============================] - 41s - loss: 1.3109 - acc: 0.6295 - val_loss: 0.8128 - val_acc: 0.7621\n",
      "Epoch 22/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2706 - acc: 0.6401Epoch 00021: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.2697 - acc: 0.6403 - val_loss: 0.8256 - val_acc: 0.7558\n",
      "Epoch 23/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2561 - acc: 0.6373Epoch 00022: val_acc did not improve\n",
      "39/39 [==============================] - 34s - loss: 1.2580 - acc: 0.6370 - val_loss: 0.7965 - val_acc: 0.7701\n",
      "Epoch 24/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2438 - acc: 0.6443Epoch 00023: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.2375 - acc: 0.6454 - val_loss: 0.7724 - val_acc: 0.7725\n",
      "Epoch 25/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2210 - acc: 0.6482Epoch 00024: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.2241 - acc: 0.6479 - val_loss: 0.7779 - val_acc: 0.7701\n",
      "Epoch 26/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2221 - acc: 0.6495Epoch 00025: val_acc improved from 0.77247 to 0.77407, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.2176 - acc: 0.6509 - val_loss: 0.7763 - val_acc: 0.7741\n",
      "Epoch 27/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.2069 - acc: 0.6536Epoch 00026: val_acc improved from 0.77407 to 0.78123, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.2052 - acc: 0.6535 - val_loss: 0.7447 - val_acc: 0.7812\n",
      "Epoch 28/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.1926 - acc: 0.6491Epoch 00027: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.1915 - acc: 0.6503 - val_loss: 0.7863 - val_acc: 0.7669\n",
      "Epoch 29/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.1527 - acc: 0.6628Epoch 00028: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.1514 - acc: 0.6640 - val_loss: 0.7557 - val_acc: 0.7772\n",
      "Epoch 30/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.1503 - acc: 0.6615Epoch 00029: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.1455 - acc: 0.6635 - val_loss: 0.7870 - val_acc: 0.7637\n",
      "Epoch 31/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0985 - acc: 0.6748Epoch 00030: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.1057 - acc: 0.6731 - val_loss: 0.7477 - val_acc: 0.7780\n",
      "Epoch 32/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.1557 - acc: 0.6681Epoch 00031: val_acc improved from 0.78123 to 0.78520, saving model to best.kerasModelWeights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 35s - loss: 1.1505 - acc: 0.6692 - val_loss: 0.7413 - val_acc: 0.7852\n",
      "Epoch 33/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.1288 - acc: 0.6699Epoch 00032: val_acc improved from 0.78520 to 0.78918, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.1319 - acc: 0.6691 - val_loss: 0.7193 - val_acc: 0.7892\n",
      "Epoch 34/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0980 - acc: 0.6796Epoch 00033: val_acc improved from 0.78918 to 0.79475, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 35s - loss: 1.0987 - acc: 0.6802 - val_loss: 0.7441 - val_acc: 0.7947\n",
      "Epoch 35/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0925 - acc: 0.6840Epoch 00034: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0962 - acc: 0.6828 - val_loss: 0.7547 - val_acc: 0.7669\n",
      "Epoch 36/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0829 - acc: 0.6812Epoch 00035: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0858 - acc: 0.6815 - val_loss: 0.7319 - val_acc: 0.7844\n",
      "Epoch 37/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0675 - acc: 0.6888Epoch 00036: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0631 - acc: 0.6893 - val_loss: 0.7440 - val_acc: 0.7836\n",
      "Epoch 38/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0610 - acc: 0.6873Epoch 00037: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0576 - acc: 0.6882 - val_loss: 0.7780 - val_acc: 0.7693\n",
      "Epoch 39/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0506 - acc: 0.6883Epoch 00038: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0489 - acc: 0.6880 - val_loss: 0.7235 - val_acc: 0.7892\n",
      "Epoch 40/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0128 - acc: 0.6896Epoch 00039: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0237 - acc: 0.6870 - val_loss: 0.7190 - val_acc: 0.7868\n",
      "Epoch 41/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0245 - acc: 0.6914Epoch 00040: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 1.0275 - acc: 0.6913 - val_loss: 0.7525 - val_acc: 0.7772\n",
      "Epoch 42/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0097 - acc: 0.6968Epoch 00041: val_acc did not improve\n",
      "39/39 [==============================] - 39s - loss: 1.0099 - acc: 0.6959 - val_loss: 0.7617 - val_acc: 0.7582\n",
      "Epoch 43/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 1.0416 - acc: 0.6893Epoch 00042: val_acc did not improve\n",
      "39/39 [==============================] - 43s - loss: 1.0364 - acc: 0.6901 - val_loss: 0.7306 - val_acc: 0.7844\n",
      "Epoch 44/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 1.0220 - acc: 0.7039Epoch 00043: val_acc did not improve\n",
      "39/39 [==============================] - 36s - loss: 1.0279 - acc: 0.7022 - val_loss: 0.7457 - val_acc: 0.7868\n",
      "Epoch 45/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.9826 - acc: 0.7034Epoch 00044: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 0.9815 - acc: 0.7034 - val_loss: 0.7188 - val_acc: 0.7844\n",
      "Epoch 46/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 0.9916 - acc: 0.7043Epoch 00045: val_acc did not improve\n",
      "39/39 [==============================] - 35s - loss: 0.9918 - acc: 0.7047 - val_loss: 0.7031 - val_acc: 0.7852\n",
      "Epoch 47/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9609 - acc: 0.7125Epoch 00046: val_acc did not improve\n",
      "39/39 [==============================] - 49s - loss: 0.9625 - acc: 0.7122 - val_loss: 0.7321 - val_acc: 0.7828\n",
      "Epoch 48/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9380 - acc: 0.7120Epoch 00047: val_acc did not improve\n",
      "39/39 [==============================] - 52s - loss: 0.9378 - acc: 0.7114 - val_loss: 0.7150 - val_acc: 0.7820\n",
      "Epoch 49/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9512 - acc: 0.7138Epoch 00048: val_acc did not improve\n",
      "39/39 [==============================] - 52s - loss: 0.9507 - acc: 0.7131 - val_loss: 0.7146 - val_acc: 0.7868\n",
      "Epoch 50/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9596 - acc: 0.7111Epoch 00049: val_acc did not improve\n",
      "39/39 [==============================] - 50s - loss: 0.9617 - acc: 0.7109 - val_loss: 0.7176 - val_acc: 0.7860\n",
      "Epoch 51/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9256 - acc: 0.7216Epoch 00050: val_acc did not improve\n",
      "39/39 [==============================] - 50s - loss: 0.9279 - acc: 0.7212 - val_loss: 0.7033 - val_acc: 0.7932\n",
      "Epoch 52/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9238 - acc: 0.7099Epoch 00051: val_acc did not improve\n",
      "39/39 [==============================] - 50s - loss: 0.9265 - acc: 0.7100 - val_loss: 0.7125 - val_acc: 0.7812\n",
      "Epoch 53/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9302 - acc: 0.7252Epoch 00052: val_acc did not improve\n",
      "39/39 [==============================] - 49s - loss: 0.9294 - acc: 0.7245 - val_loss: 0.7011 - val_acc: 0.7900\n",
      "Epoch 54/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9523 - acc: 0.7127Epoch 00053: val_acc improved from 0.79475 to 0.79714, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 50s - loss: 0.9451 - acc: 0.7149 - val_loss: 0.6812 - val_acc: 0.7971\n",
      "Epoch 55/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9278 - acc: 0.7207Epoch 00054: val_acc did not improve\n",
      "39/39 [==============================] - 50s - loss: 0.9281 - acc: 0.7208 - val_loss: 0.6877 - val_acc: 0.7844\n",
      "Epoch 56/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9396 - acc: 0.7062Epoch 00055: val_acc did not improve\n",
      "39/39 [==============================] - 57s - loss: 0.9351 - acc: 0.7079 - val_loss: 0.6998 - val_acc: 0.7900\n",
      "Epoch 57/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.8853 - acc: 0.7339Epoch 00056: val_acc did not improve\n",
      "39/39 [==============================] - 58s - loss: 0.8857 - acc: 0.7337 - val_loss: 0.6872 - val_acc: 0.7947\n",
      "Epoch 58/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.9119 - acc: 0.7230Epoch 00057: val_acc did not improve\n",
      "39/39 [==============================] - 68s - loss: 0.9129 - acc: 0.7227 - val_loss: 0.7156 - val_acc: 0.7677\n",
      "Epoch 59/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.8824 - acc: 0.7296Epoch 00058: val_acc did not improve\n",
      "39/39 [==============================] - 69s - loss: 0.8820 - acc: 0.7298 - val_loss: 0.7357 - val_acc: 0.7772\n",
      "Epoch 60/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.8861 - acc: 0.7218Epoch 00059: val_acc did not improve\n",
      "39/39 [==============================] - 71s - loss: 0.8892 - acc: 0.7209 - val_loss: 0.6950 - val_acc: 0.7860\n",
      "Epoch 61/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.8735 - acc: 0.7309Epoch 00060: val_acc did not improve\n",
      "39/39 [==============================] - 74s - loss: 0.8749 - acc: 0.7300 - val_loss: 0.7055 - val_acc: 0.7971\n",
      "Epoch 62/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.8599 - acc: 0.7280Epoch 00061: val_acc did not improve\n",
      "39/39 [==============================] - 75s - loss: 0.8583 - acc: 0.7274 - val_loss: 0.7265 - val_acc: 0.7860\n",
      "Epoch 63/500\n",
      "38/39 [============================>.] - ETA: 1s - loss: 0.8569 - acc: 0.7356Epoch 00062: val_acc did not improve\n",
      "39/39 [==============================] - 71s - loss: 0.8575 - acc: 0.7351 - val_loss: 0.6701 - val_acc: 0.7940\n",
      "Epoch 64/500\n",
      "31/39 [======================>.......] - ETA: 13s - loss: 0.8497 - acc: 0.7451"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adamax',  \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# We want to keep the best model. This callback will store \n",
    "# in a file the weights of the model with the highest validation accuracy  \n",
    "saveBestModel = ModelCheckpoint(\"best.kerasModelWeights\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Make the model learn using the image generator\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=128),\n",
    "                samples_per_epoch=len(X_train),\n",
    "                epochs=500, \n",
    "                validation_data=(X_val, Y_val),\n",
    "                callbacks=[saveBestModel],\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6208/6220 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Predict the class (give the index in the one-hot vector of the most probable class)\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "# Translate integers to character labels\n",
    "vInt2label = np.vectorize(int2label)\n",
    "Y_test_pred = vInt2label(Y_test_pred)\n",
    "\n",
    "# Save the predicitions in Kaggle format\n",
    "np.savetxt(path+\"/CNN_pred.csv\", np.c_[range(6284,len(Y_test_pred)+6284),Y_test_pred], delimiter=',', header = 'ID,Class', comments = '', fmt='%s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
