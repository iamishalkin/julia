{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from skimage import transform, filters, exposure\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.layers.convolutional import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6220, 20, 20, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "from natsort import natsorted\n",
    "from scipy.misc import imread\n",
    "import random\n",
    "random.seed( 42 ) \n",
    "\n",
    "nb_classes=62\n",
    "# Path of data files\n",
    "path = \"/home/ivan/python/julia/data\"\n",
    " \n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 20, 20\n",
    " \n",
    " \n",
    "\n",
    "### Images preprocessing ###\n",
    "\n",
    "for setType in [\"test\",\"train\"]:\n",
    "    # We have to make sure files are sorted according to labels, even if they don't have trailing zeros\n",
    "    files = natsorted(glob.glob(path + \"/\"+setType+\"/*\"))\n",
    "    \"\"\"\n",
    "    if setType == 'test':\n",
    "        X_test = np.array([np.array(Image.open(fname)) for fname in files])\n",
    "    else:\n",
    "        X_train = np.array([np.array(Image.open(fname)) for fname in files])\n",
    "    \"\"\"\n",
    "    if setType == 'test':\n",
    "        X_test = np.array([np.array(imread(fname, flatten=True)) for fname in files])\n",
    "    else:\n",
    "        X_train = np.array([np.array(imread(fname, flatten=True)) for fname in files])\n",
    "X_test=X_test[:,:,:,np.newaxis]\n",
    "X_train=X_train[:,:,:,np.newaxis]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_test.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label2int(ch):\n",
    "    asciiVal = ord(ch)\n",
    "    if(asciiVal<=57): #0-9\n",
    "        asciiVal-=48\n",
    "    elif(asciiVal<=90): #A-Z\n",
    "        asciiVal-=55\n",
    "    else: #a-z\n",
    "        asciiVal-=61\n",
    "    return asciiVal\n",
    "    \n",
    "def int2label(i):\n",
    "    if(i<=9): #0-9\n",
    "        i+=48\n",
    "    elif(i<=35): #A-Z\n",
    "        i+=55\n",
    "    else: #a-z\n",
    "        i+=61\n",
    "    return chr(i)\n",
    "# Load labels\n",
    "y_train = pd.read_csv(\"/home/ivan/python/julia/trainLabels.csv\").values[:,1] #Keep only label\n",
    " \n",
    "# Convert labels to one-hot vectors\n",
    "Y_train = np.zeros((y_train.shape[0], len(np.unique(y_train))))\n",
    " \n",
    "for i in range(y_train.shape[0]):\n",
    "    Y_train[i][label2int(y_train[i])] = 1 # One-hot\n",
    "Y_train_all = Y_train.copy()\n",
    "X_train_all = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = \\\n",
    "        train_test_split(X_train_all, Y_train_all, test_size=0.2, stratify=np.argmax(Y_train_all, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:56: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, concatenate, Conv2DTranspose\n",
    "inputs = Input((img_rows, img_cols, 1))\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv3), conv2], axis=3)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv1], axis=3)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "\"\"\"\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\"\"\"\n",
    "\n",
    "flat = Flatten()(conv7)\n",
    "dense1 = Dense(2048, activation=\"relu\")(flat)\n",
    "drp1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(2048, activation=\"relu\")(drp1)\n",
    "drp2 = Dropout(0.5)(dense2)\n",
    "dense3 = Dense(nb_classes, activation=\"softmax\")(drp1)\n",
    "\n",
    "model = Model(input=inputs, output=dense3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### LEARNING ###\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "# First, use AdaDelta for some epochs because AdaMax gets stuck\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adadelta(),  \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5026 samples, validate on 1257 samples\n",
      "Epoch 1/20\n",
      "5026/5026 [==============================] - 284s - loss: 3.8626 - acc: 0.0609 - val_loss: 3.7924 - val_acc: 0.0573\n",
      "Epoch 2/20\n",
      "1664/5026 [========>.....................] - ETA: 182s - loss: 3.7948 - acc: 0.0523"
     ]
    }
   ],
   "source": [
    "# 20 epochs is sufficient\n",
    "model.fit(X_train, Y_train, batch_size=128,\n",
    "                    #nb_epoch=20, \n",
    "                    epochs=20,\n",
    "                    validation_data=(X_val, Y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parametrize the image augmentation class\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.15,\n",
    "    height_shift_range = 0.15,\n",
    "    shear_range = 0.4,\n",
    "    zoom_range = 0.3,                    \n",
    "    channel_shift_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=500, steps_per_epoch=39, callbacks=[<keras.ca..., validation_data=(array([[[..., verbose=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7823 - acc: 0.0722Epoch 00000: val_acc improved from -inf to 0.07319, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 6s - loss: 3.7842 - acc: 0.0725 - val_loss: 3.7662 - val_acc: 0.0732\n",
      "Epoch 2/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7747 - acc: 0.0713Epoch 00001: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7721 - acc: 0.0711 - val_loss: 3.7663 - val_acc: 0.0732\n",
      "Epoch 3/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7779 - acc: 0.0713Epoch 00002: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7788 - acc: 0.0713 - val_loss: 3.7652 - val_acc: 0.0732\n",
      "Epoch 4/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7716 - acc: 0.0691Epoch 00003: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7738 - acc: 0.0693 - val_loss: 3.7651 - val_acc: 0.0732\n",
      "Epoch 5/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7677 - acc: 0.0725Epoch 00004: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7672 - acc: 0.0726 - val_loss: 3.7649 - val_acc: 0.0732\n",
      "Epoch 6/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7790 - acc: 0.0721Epoch 00005: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7788 - acc: 0.0726 - val_loss: 3.7646 - val_acc: 0.0732\n",
      "Epoch 7/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7688 - acc: 0.0734Epoch 00006: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7689 - acc: 0.0731 - val_loss: 3.7645 - val_acc: 0.0732\n",
      "Epoch 8/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7779 - acc: 0.0711Epoch 00007: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7780 - acc: 0.0711 - val_loss: 3.7644 - val_acc: 0.0732\n",
      "Epoch 9/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7739 - acc: 0.0716Epoch 00008: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7704 - acc: 0.0720 - val_loss: 3.7632 - val_acc: 0.0732\n",
      "Epoch 10/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7773 - acc: 0.0719Epoch 00009: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7807 - acc: 0.0713 - val_loss: 3.7632 - val_acc: 0.0732\n",
      "Epoch 11/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7693 - acc: 0.0722Epoch 00010: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7684 - acc: 0.0728 - val_loss: 3.7629 - val_acc: 0.0732\n",
      "Epoch 12/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7932 - acc: 0.0684Epoch 00011: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7936 - acc: 0.0682 - val_loss: 3.7621 - val_acc: 0.0732\n",
      "Epoch 13/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7696 - acc: 0.0786Epoch 00012: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7682 - acc: 0.0776 - val_loss: 3.7626 - val_acc: 0.0732\n",
      "Epoch 14/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7629 - acc: 0.0723Epoch 00013: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7621 - acc: 0.0727 - val_loss: 3.7612 - val_acc: 0.0732\n",
      "Epoch 15/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7734 - acc: 0.0700Epoch 00014: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7739 - acc: 0.0694 - val_loss: 3.7601 - val_acc: 0.0732\n",
      "Epoch 16/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7651 - acc: 0.0757Epoch 00015: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7683 - acc: 0.0757 - val_loss: 3.7602 - val_acc: 0.0732\n",
      "Epoch 17/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7615 - acc: 0.0762Epoch 00016: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7605 - acc: 0.0766 - val_loss: 3.7584 - val_acc: 0.0732\n",
      "Epoch 18/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7724 - acc: 0.0687Epoch 00017: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7712 - acc: 0.0696 - val_loss: 3.7555 - val_acc: 0.0732\n",
      "Epoch 19/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7705 - acc: 0.0719Epoch 00018: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7707 - acc: 0.0726 - val_loss: 3.7569 - val_acc: 0.0732\n",
      "Epoch 20/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7826 - acc: 0.0711Epoch 00019: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7817 - acc: 0.0705 - val_loss: 3.7550 - val_acc: 0.0732\n",
      "Epoch 21/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7657 - acc: 0.0773Epoch 00020: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7641 - acc: 0.0769 - val_loss: 3.7521 - val_acc: 0.0732\n",
      "Epoch 22/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7681 - acc: 0.0695Epoch 00021: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7687 - acc: 0.0685 - val_loss: 3.7469 - val_acc: 0.0732\n",
      "Epoch 23/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7612 - acc: 0.0760Epoch 00022: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7641 - acc: 0.0765 - val_loss: 3.7438 - val_acc: 0.0732\n",
      "Epoch 24/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7490 - acc: 0.0689Epoch 00023: val_acc improved from 0.07319 to 0.08035, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7474 - acc: 0.0691 - val_loss: 3.7413 - val_acc: 0.0804\n",
      "Epoch 25/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7597 - acc: 0.0817Epoch 00024: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7615 - acc: 0.0814 - val_loss: 3.7359 - val_acc: 0.0732\n",
      "Epoch 26/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7548 - acc: 0.0745Epoch 00025: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7523 - acc: 0.0748 - val_loss: 3.7321 - val_acc: 0.0732\n",
      "Epoch 27/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7603 - acc: 0.0708Epoch 00026: val_acc improved from 0.08035 to 0.08671, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7584 - acc: 0.0708 - val_loss: 3.7272 - val_acc: 0.0867\n",
      "Epoch 28/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7443 - acc: 0.0782Epoch 00027: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7452 - acc: 0.0780 - val_loss: 3.7209 - val_acc: 0.0732\n",
      "Epoch 29/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7472 - acc: 0.0751Epoch 00028: val_acc improved from 0.08671 to 0.09865, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7489 - acc: 0.0756 - val_loss: 3.7176 - val_acc: 0.0986\n",
      "Epoch 30/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7437 - acc: 0.0779Epoch 00029: val_acc improved from 0.09865 to 0.10660, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7454 - acc: 0.0769 - val_loss: 3.7094 - val_acc: 0.1066\n",
      "Epoch 31/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7448 - acc: 0.0767Epoch 00030: val_acc improved from 0.10660 to 0.11058, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7451 - acc: 0.0768 - val_loss: 3.6908 - val_acc: 0.1106\n",
      "Epoch 32/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7332 - acc: 0.0763Epoch 00031: val_acc improved from 0.11058 to 0.11297, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7324 - acc: 0.0758 - val_loss: 3.6762 - val_acc: 0.1130\n",
      "Epoch 33/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7196 - acc: 0.0893Epoch 00032: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7207 - acc: 0.0890 - val_loss: 3.6618 - val_acc: 0.1114\n",
      "Epoch 34/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7205 - acc: 0.0885Epoch 00033: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.7183 - acc: 0.0884 - val_loss: 3.6483 - val_acc: 0.1074\n",
      "Epoch 35/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7219 - acc: 0.0880Epoch 00034: val_acc improved from 0.11297 to 0.11456, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 4s - loss: 3.7238 - acc: 0.0877 - val_loss: 3.6457 - val_acc: 0.1146\n",
      "Epoch 36/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7147 - acc: 0.0883Epoch 00035: val_acc improved from 0.11456 to 0.11774, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 4s - loss: 3.7148 - acc: 0.0888 - val_loss: 3.6295 - val_acc: 0.1177\n",
      "Epoch 37/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7011 - acc: 0.0976Epoch 00036: val_acc improved from 0.11774 to 0.11933, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 4s - loss: 3.7001 - acc: 0.0979 - val_loss: 3.6265 - val_acc: 0.1193\n",
      "Epoch 38/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7093 - acc: 0.0876Epoch 00037: val_acc improved from 0.11933 to 0.12172, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7077 - acc: 0.0883 - val_loss: 3.6115 - val_acc: 0.1217\n",
      "Epoch 39/500\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 3.6970 - acc: 0.0921Epoch 00038: val_acc improved from 0.12172 to 0.12251, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.7040 - acc: 0.0925 - val_loss: 3.5979 - val_acc: 0.1225\n",
      "Epoch 40/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6925 - acc: 0.0917Epoch 00039: val_acc improved from 0.12251 to 0.12729, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6894 - acc: 0.0901 - val_loss: 3.5864 - val_acc: 0.1273\n",
      "Epoch 41/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.7063 - acc: 0.0915Epoch 00040: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.7037 - acc: 0.0917 - val_loss: 3.5863 - val_acc: 0.1249\n",
      "Epoch 42/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6914 - acc: 0.0896Epoch 00041: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6914 - acc: 0.0899 - val_loss: 3.5874 - val_acc: 0.1249\n",
      "Epoch 43/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6920 - acc: 0.0957Epoch 00042: val_acc improved from 0.12729 to 0.13286, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6904 - acc: 0.0950 - val_loss: 3.5686 - val_acc: 0.1329\n",
      "Epoch 44/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6746 - acc: 0.1002Epoch 00043: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6785 - acc: 0.1002 - val_loss: 3.5543 - val_acc: 0.1329\n",
      "Epoch 45/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6803 - acc: 0.0984Epoch 00044: val_acc improved from 0.13286 to 0.13365, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6804 - acc: 0.0977 - val_loss: 3.5498 - val_acc: 0.1337\n",
      "Epoch 46/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6801 - acc: 0.0963Epoch 00045: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6849 - acc: 0.0960 - val_loss: 3.5426 - val_acc: 0.1249\n",
      "Epoch 47/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6764 - acc: 0.1032Epoch 00046: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6778 - acc: 0.1029 - val_loss: 3.5491 - val_acc: 0.1233\n",
      "Epoch 48/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6620 - acc: 0.0971Epoch 00047: val_acc improved from 0.13365 to 0.13445, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6608 - acc: 0.0969 - val_loss: 3.5251 - val_acc: 0.1344\n",
      "Epoch 49/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6685 - acc: 0.1011Epoch 00048: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6678 - acc: 0.1005 - val_loss: 3.5158 - val_acc: 0.1337\n",
      "Epoch 50/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6718 - acc: 0.0976Epoch 00049: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6682 - acc: 0.0985 - val_loss: 3.5078 - val_acc: 0.1281\n",
      "Epoch 51/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6485 - acc: 0.1016Epoch 00050: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6501 - acc: 0.1014 - val_loss: 3.5093 - val_acc: 0.1337\n",
      "Epoch 52/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6473 - acc: 0.1008Epoch 00051: val_acc improved from 0.13445 to 0.13604, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6472 - acc: 0.1013 - val_loss: 3.4863 - val_acc: 0.1360\n",
      "Epoch 53/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6738 - acc: 0.1021Epoch 00052: val_acc improved from 0.13604 to 0.13683, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6745 - acc: 0.1015 - val_loss: 3.4821 - val_acc: 0.1368\n",
      "Epoch 54/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6382 - acc: 0.1039Epoch 00053: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6411 - acc: 0.1038 - val_loss: 3.4831 - val_acc: 0.1257\n",
      "Epoch 55/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6400 - acc: 0.1066Epoch 00054: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6407 - acc: 0.1066 - val_loss: 3.4769 - val_acc: 0.1329\n",
      "Epoch 56/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6505 - acc: 0.1096Epoch 00055: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6544 - acc: 0.1086 - val_loss: 3.4658 - val_acc: 0.1241\n",
      "Epoch 57/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6681 - acc: 0.0958Epoch 00056: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6713 - acc: 0.0943 - val_loss: 3.4626 - val_acc: 0.1321\n",
      "Epoch 58/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6180 - acc: 0.1092Epoch 00057: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6222 - acc: 0.1078 - val_loss: 3.4624 - val_acc: 0.1352\n",
      "Epoch 59/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6258 - acc: 0.1078Epoch 00058: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6286 - acc: 0.1086 - val_loss: 3.4414 - val_acc: 0.1344\n",
      "Epoch 60/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6326 - acc: 0.1084Epoch 00059: val_acc improved from 0.13683 to 0.13842, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6319 - acc: 0.1098 - val_loss: 3.4369 - val_acc: 0.1384\n",
      "Epoch 61/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6213 - acc: 0.1065Epoch 00060: val_acc improved from 0.13842 to 0.14399, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6208 - acc: 0.1053 - val_loss: 3.4292 - val_acc: 0.1440\n",
      "Epoch 62/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6210 - acc: 0.1108Epoch 00061: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6229 - acc: 0.1097 - val_loss: 3.4199 - val_acc: 0.1344\n",
      "Epoch 63/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6205 - acc: 0.1070Epoch 00062: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6190 - acc: 0.1077 - val_loss: 3.4166 - val_acc: 0.1368\n",
      "Epoch 64/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6058 - acc: 0.1127Epoch 00063: val_acc improved from 0.14399 to 0.15274, saving model to best.kerasModelWeights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 5s - loss: 3.6078 - acc: 0.1122 - val_loss: 3.4187 - val_acc: 0.1527\n",
      "Epoch 65/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6348 - acc: 0.1190Epoch 00064: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6345 - acc: 0.1185 - val_loss: 3.3999 - val_acc: 0.1512\n",
      "Epoch 66/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6126 - acc: 0.1085Epoch 00065: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6117 - acc: 0.1086 - val_loss: 3.3971 - val_acc: 0.1480\n",
      "Epoch 67/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6036 - acc: 0.1140Epoch 00066: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6035 - acc: 0.1133 - val_loss: 3.3981 - val_acc: 0.1472\n",
      "Epoch 68/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6063 - acc: 0.1174Epoch 00067: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.6062 - acc: 0.1164 - val_loss: 3.3820 - val_acc: 0.1432\n",
      "Epoch 69/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6039 - acc: 0.1135Epoch 00068: val_acc improved from 0.15274 to 0.15752, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.6022 - acc: 0.1146 - val_loss: 3.3812 - val_acc: 0.1575\n",
      "Epoch 70/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6004 - acc: 0.1094Epoch 00069: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5980 - acc: 0.1100 - val_loss: 3.3727 - val_acc: 0.1424\n",
      "Epoch 71/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.6019 - acc: 0.1122Epoch 00070: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5984 - acc: 0.1137 - val_loss: 3.3683 - val_acc: 0.1480\n",
      "Epoch 72/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5868 - acc: 0.1203Epoch 00071: val_acc improved from 0.15752 to 0.15990, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5867 - acc: 0.1203 - val_loss: 3.3590 - val_acc: 0.1599\n",
      "Epoch 73/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5875 - acc: 0.1115Epoch 00072: val_acc improved from 0.15990 to 0.16866, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5890 - acc: 0.1117 - val_loss: 3.3528 - val_acc: 0.1687\n",
      "Epoch 74/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5835 - acc: 0.1115Epoch 00073: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5842 - acc: 0.1119 - val_loss: 3.3475 - val_acc: 0.1583\n",
      "Epoch 75/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5917 - acc: 0.1111Epoch 00074: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5886 - acc: 0.1121 - val_loss: 3.3399 - val_acc: 0.1575\n",
      "Epoch 76/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5753 - acc: 0.1166Epoch 00075: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.5765 - acc: 0.1170 - val_loss: 3.3356 - val_acc: 0.1543\n",
      "Epoch 77/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5796 - acc: 0.1184Epoch 00076: val_acc did not improve\n",
      "39/39 [==============================] - 4s - loss: 3.5850 - acc: 0.1172 - val_loss: 3.3373 - val_acc: 0.1631\n",
      "Epoch 78/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5673 - acc: 0.1253Epoch 00077: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5687 - acc: 0.1253 - val_loss: 3.3237 - val_acc: 0.1575\n",
      "Epoch 79/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5708 - acc: 0.1135Epoch 00078: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5733 - acc: 0.1129 - val_loss: 3.3330 - val_acc: 0.1615\n",
      "Epoch 80/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5748 - acc: 0.1199Epoch 00079: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5759 - acc: 0.1198 - val_loss: 3.3233 - val_acc: 0.1615\n",
      "Epoch 81/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5808 - acc: 0.1180Epoch 00080: val_acc improved from 0.16866 to 0.17025, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5793 - acc: 0.1186 - val_loss: 3.3290 - val_acc: 0.1702\n",
      "Epoch 82/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5773 - acc: 0.1227Epoch 00081: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5786 - acc: 0.1229 - val_loss: 3.3216 - val_acc: 0.1687\n",
      "Epoch 83/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5686 - acc: 0.1269Epoch 00082: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5679 - acc: 0.1270 - val_loss: 3.3111 - val_acc: 0.1559\n",
      "Epoch 84/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5649 - acc: 0.1228Epoch 00083: val_acc improved from 0.17025 to 0.17343, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5642 - acc: 0.1239 - val_loss: 3.3136 - val_acc: 0.1734\n",
      "Epoch 85/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5622 - acc: 0.1288Epoch 00084: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5625 - acc: 0.1279 - val_loss: 3.2997 - val_acc: 0.1631\n",
      "Epoch 86/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5677 - acc: 0.1243Epoch 00085: val_acc improved from 0.17343 to 0.17422, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5689 - acc: 0.1235 - val_loss: 3.3055 - val_acc: 0.1742\n",
      "Epoch 87/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5691 - acc: 0.1225Epoch 00086: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5676 - acc: 0.1220 - val_loss: 3.3000 - val_acc: 0.1695\n",
      "Epoch 88/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5456 - acc: 0.1246Epoch 00087: val_acc improved from 0.17422 to 0.17422, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5445 - acc: 0.1240 - val_loss: 3.2971 - val_acc: 0.1742\n",
      "Epoch 89/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5543 - acc: 0.1249Epoch 00088: val_acc improved from 0.17422 to 0.17979, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5552 - acc: 0.1245 - val_loss: 3.2839 - val_acc: 0.1798\n",
      "Epoch 90/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5708 - acc: 0.1305Epoch 00089: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5706 - acc: 0.1299 - val_loss: 3.2803 - val_acc: 0.1766\n",
      "Epoch 91/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5468 - acc: 0.1228Epoch 00090: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5475 - acc: 0.1225 - val_loss: 3.2809 - val_acc: 0.1687\n",
      "Epoch 92/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5361 - acc: 0.1291Epoch 00091: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5362 - acc: 0.1288 - val_loss: 3.2676 - val_acc: 0.1663\n",
      "Epoch 93/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5514 - acc: 0.1256Epoch 00092: val_acc improved from 0.17979 to 0.18138, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5518 - acc: 0.1260 - val_loss: 3.2849 - val_acc: 0.1814\n",
      "Epoch 94/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5633 - acc: 0.1261Epoch 00093: val_acc improved from 0.18138 to 0.18377, saving model to best.kerasModelWeights\n",
      "39/39 [==============================] - 5s - loss: 3.5625 - acc: 0.1257 - val_loss: 3.2697 - val_acc: 0.1838\n",
      "Epoch 95/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5474 - acc: 0.1252Epoch 00094: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5469 - acc: 0.1250 - val_loss: 3.2691 - val_acc: 0.1822\n",
      "Epoch 96/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5490 - acc: 0.1228Epoch 00095: val_acc improved from 0.18377 to 0.18934, saving model to best.kerasModelWeights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 5s - loss: 3.5505 - acc: 0.1231 - val_loss: 3.2989 - val_acc: 0.1893\n",
      "Epoch 97/500\n",
      "38/39 [============================>.] - ETA: 0s - loss: 3.5234 - acc: 0.1201Epoch 00096: val_acc did not improve\n",
      "39/39 [==============================] - 5s - loss: 3.5188 - acc: 0.1216 - val_loss: 3.2723 - val_acc: 0.1862\n",
      "Epoch 98/500\n",
      "19/39 [=============>................] - ETA: 2s - loss: 3.5525 - acc: 0.1348"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adamax',  \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# We want to keep the best model. This callback will store \n",
    "# in a file the weights of the model with the highest validation accuracy  \n",
    "saveBestModel = ModelCheckpoint(\"best.kerasModelWeights\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# Make the model learn using the image generator\n",
    "model.fit_generator(datagen.flow(X_train, Y_train, batch_size=128),\n",
    "                samples_per_epoch=len(X_train),\n",
    "                epochs=500, \n",
    "                validation_data=(X_val, Y_val),\n",
    "                callbacks=[saveBestModel],\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6208/6220 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# Predict the class (give the index in the one-hot vector of the most probable class)\n",
    "Y_test_pred = model.predict_classes(X_test)\n",
    "\n",
    "# Translate integers to character labels\n",
    "vInt2label = np.vectorize(int2label)\n",
    "Y_test_pred = vInt2label(Y_test_pred)\n",
    "\n",
    "# Save the predicitions in Kaggle format\n",
    "np.savetxt(path+\"/CNN_pred.csv\", np.c_[range(6284,len(Y_test_pred)+6284),Y_test_pred], delimiter=',', header = 'ID,Class', comments = '', fmt='%s')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:25: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:29: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\"concat\" mode can only merge layers with matching output shapes except for the concat axis. Layer shapes: [(None, 4, 4, 256), (None, 5, 5, 128)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-534fbc7cf316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mconv6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mup7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mconv7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mconv7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(inputs, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, name)\u001b[0m\n\u001b[1;32m    456\u001b[0m                             \u001b[0mnode_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mtensor_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                             name=name)\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, output_shape, output_mask, arguments, node_indices, tensor_indices, name)\u001b[0m\n\u001b[1;32m    108\u001b[0m             self._arguments_validation(layers, mode,\n\u001b[1;32m    109\u001b[0m                                        \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdot_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                                        node_indices, tensor_indices)\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py\u001b[0m in \u001b[0;36m_arguments_validation\u001b[0;34m(self, layers, mode, concat_axis, dot_axes, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    188\u001b[0m                                  \u001b[0;34m'layers with matching '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                                  \u001b[0;34m'output shapes except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                                  'Layer shapes: %s' % (input_shapes))\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \"concat\" mode can only merge layers with matching output shapes except for the concat axis. Layer shapes: [(None, 4, 4, 256), (None, 5, 5, 128)]"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout, concatenate, Conv2DTranspose\n",
    "inputs = Input((img_rows, img_cols, 1))\n",
    "conv1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "conv1 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "conv2 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "conv3 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "\n",
    "conv4 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "conv4 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "conv5 = Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")(conv5)\n",
    "\n",
    "up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=3)\n",
    "conv6 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(up6)\n",
    "conv6 = Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(conv6)\n",
    "\n",
    "up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=3)\n",
    "conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
    "conv7 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
    "\n",
    "up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=3)\n",
    "conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
    "conv8 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
    "\n",
    "up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=3)\n",
    "conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
    "conv9 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#conv10 = Convolution2D(nb_classes,1, activation='softmax')(conv5)\n",
    "flat = Flatten()(conv9)\n",
    "dense1 = Dense(2048, activation=\"relu\")(flat)\n",
    "drp1 = Dropout(0.5)(dense1)\n",
    "dense2 = Dense(2048, activation=\"relu\")(drp1)\n",
    "drp2 = Dropout(0.5)(dense2)\n",
    "dense3 = Dense(nb_classes, activation=\"softmax\")(drp1)\n",
    "\n",
    "model = Model(input=inputs, output=dense3)\n",
    "#model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[ 'accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
